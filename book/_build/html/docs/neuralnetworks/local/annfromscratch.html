
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Neural Network from Scratch &#8212; Data Analytics &amp; Insights in Electricity Markets</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.acff12b8f9c144ce68a297486a2fa670.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/custom.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="../../../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="shortcut icon" href="../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Datasets" href="../../datasets/datasets.html" />
    <link rel="prev" title="Using Local Machine" href="../local.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
      <img src="../../../_static/neural.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Analytics & Insights in Electricity Markets</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Case Studies
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../electricitymarkets/demand.html">
   Forecasting Regional Electricity Demand
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../electricitymarkets/clearingprice.html">
   Market Clearing Price
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../electricitymarkets/energymarket.html">
   Geocoding of Market Participants
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../neuralnetworks.html">
   Neural Networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../colab.html">
     Using Colab
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="../local.html">
     Using Local Machine
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Neural Network from Scratch
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../datasets/datasets.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../datasets/philenergy.html">
     Philippine Electricity Market
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../datasets/philenergy/datamps.html">
       Market Prices and Schedules Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../datasets/philenergy/dataclearingprice.html">
       Market Clearing Price Data
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../datasets/philenergy/dataregionaldemand.html">
       Regional Electricity Demand Data
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../datasets/hrdatasetv14.html">
     Human Resources Analytics
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Optimization
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../opti/lp.html">
   Using Julia
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../opti/dispatch.html">
   Economic Dispatch
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Statistical Learning
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../stat/rstat.html">
   Computational Statistics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  References
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../math/linalg.html">
   Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../math/prob3.html">
   Probability Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../math/stat.html">
   Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../math/or.html">
   Operations Research
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Utilities
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../utility/functions.html">
   Functions and Classes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../utility/plotting.html">
   Plotting exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../utility/numpy.html">
   Numpy Exercise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../visualization/tableau.html">
   Tableau Dashboards
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Blog
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../blog/blog.html">
   Summary
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../blog/postlist/edatemplate.html">
     Exploratory Data Analysis Template
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../blog/postlist/sqlds.html">
     SQL for Data Scientists
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../blog/postlist/dataextract.html">
     Data Extraction Guide
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Contact me
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/contact.html">
   Info
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="neural-network-from-scratch">
<h1>Neural Network from Scratch<a class="headerlink" href="#neural-network-from-scratch" title="Permalink to this headline">¬∂</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span> 
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span> <span class="c1"># mean and standard deviation</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># For the given mean and std, draw  1,000,000 random samples from ‚àí2ùúé, +2ùúé to build a dataset</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">1000000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nbin</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">nbin</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/annfromscratch_4_0.png" src="../../../_images/annfromscratch_4_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Split the dataset into train (90%) and test(10%) </span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">count</span><span class="p">)[</span><span class="o">...</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">slicesplit</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.9</span><span class="o">*</span><span class="n">nbin</span><span class="p">)</span>
<span class="n">training</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">slicesplit</span><span class="p">,:],</span> <span class="n">X</span><span class="p">[</span><span class="n">slicesplit</span><span class="p">:,:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using pure Python3 and Numpy, build a 3-layer neural networks:</span>
<span class="c1"># - Layers: {1 ‚àí 64 ‚àí ùëÖùëíùêøùëà ‚àí 64 ‚àí ùëÖùëíùêøùëà ‚àí 64 ‚àí 1 ‚àí ùë†ùëñùëîùëöùëúùëñùëë} </span>
<span class="c1"># - Initialize the weights using a Gaussian distribution with zero mean and std=0.01.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Class Definitions</span>
<span class="k">class</span> <span class="nc">Layer_Dense</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="mf">0.01</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">biases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_neurons</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Remember input values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">biases</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dvalues</span><span class="p">):</span>
        <span class="c1"># Gradients on parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dweights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dvalues</span><span class="p">)</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">dbiases</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dvalues</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Gradient on values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dvalues</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">Activation_ReLU</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Remember input values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dvalues</span><span class="p">):</span>
        <span class="c1"># Since we need to modify original variable, </span>
        <span class="c1"># let&#39;s make a copy of values first </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span> <span class="o">=</span> <span class="n">dvalues</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="c1"># Zero gradient where input values were negative </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>


<span class="k">class</span> <span class="nc">Activation_Sigmoid</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="c1"># Remember input values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">inputs</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dvalues</span><span class="p">):</span>
    <span class="c1"># Derivative - calculates from output of the sigmoid function </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span> <span class="o">=</span> <span class="n">dvalues</span><span class="o">*</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">)</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span>
    
    
<span class="k">class</span> <span class="nc">Loss</span><span class="p">:</span>
    <span class="c1"># Calculates the data losses </span>
    <span class="c1"># given model output and ground truth values </span>
    <span class="k">def</span> <span class="nf">calculate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="c1"># Calculate sample losses </span>
        <span class="n">sample_losses</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="c1"># Calculate mean loss</span>
        <span class="n">data_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">sample_losses</span><span class="p">)</span>
        <span class="c1"># Return loss </span>
        <span class="k">return</span> <span class="n">data_loss</span>
    

<span class="k">class</span> <span class="nc">Loss_MeanSquaredError</span><span class="p">(</span><span class="n">Loss</span><span class="p">):</span> 
    <span class="c1"># Mean Squared Error loss</span>
    <span class="c1"># Forward pass</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span> <span class="c1"># Calculate loss</span>
        <span class="n">sample_losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> 
        <span class="c1"># Return losses</span>
        <span class="k">return</span> <span class="n">sample_losses</span>
    
    <span class="c1"># Backward pass</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dvalues</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
        <span class="c1"># Number of samples</span>
        <span class="n">samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dvalues</span><span class="p">)</span>
        <span class="c1"># Number of outputs in every sample</span>
        <span class="c1"># We&#39;ll use the first sample to count them </span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dvalues</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="c1"># Gradient on values</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">dvalues</span><span class="p">)</span><span class="o">/</span><span class="n">outputs</span> 
        <span class="c1"># Normalize gradient</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dinputs</span><span class="o">/</span><span class="n">samples</span>

        
<span class="k">class</span> <span class="nc">Optimizer_SGD</span><span class="p">:</span>
    <span class="c1"># Initialize optimizer - set settings</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
    
    <span class="k">def</span> <span class="nf">update_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">dweights</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">biases</span> <span class="o">+=</span> <span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">dbiases</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Network Construction</span>
<span class="n">dense1</span> <span class="o">=</span> <span class="n">Layer_Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">activation1</span> <span class="o">=</span> <span class="n">Activation_ReLU</span><span class="p">()</span>

<span class="n">dense2</span> <span class="o">=</span> <span class="n">Layer_Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">)</span>
<span class="n">activation2</span> <span class="o">=</span> <span class="n">Activation_ReLU</span><span class="p">()</span>

<span class="n">dense3</span> <span class="o">=</span> <span class="n">Layer_Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">activation3</span> <span class="o">=</span> <span class="n">Activation_Sigmoid</span><span class="p">()</span> 

<span class="n">loss_function</span> <span class="o">=</span> <span class="n">Loss_MeanSquaredError</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Optimizer_SGD</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train for 20 epochs and evaluate the performance of your network</span>
<span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">20</span>

<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span> 
    
    <span class="c1"># Training</span>
    <span class="n">avetrainloss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">training</span><span class="p">:</span> <span class="c1">#Batch size = 1</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Forward pass</span>
        <span class="n">dense1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">activation1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dense1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">dense2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">activation1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">activation2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dense2</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">dense3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">activation2</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">activation3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dense3</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">trainloss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span><span class="n">activation3</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># Backward pass </span>
        <span class="n">loss_function</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">activation3</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="n">activation3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss_function</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span> 
        <span class="n">dense3</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">activation3</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span> 
        
        <span class="n">activation2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dense3</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span> 
        <span class="n">dense2</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">activation2</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span> 
        
        <span class="n">activation1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">dense2</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span> 
        <span class="n">dense1</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">activation1</span><span class="o">.</span><span class="n">dinputs</span><span class="p">)</span>

        <span class="c1"># Update weights and biases</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">dense1</span><span class="p">)</span> 
        <span class="n">optimizer</span><span class="o">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">dense2</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">update_params</span><span class="p">(</span><span class="n">dense3</span><span class="p">)</span>
        
        <span class="n">avetrainloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trainloss</span><span class="p">)</span>
    
    <span class="c1"># Validation</span>
    <span class="n">avetestloss</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">test</span><span class="p">:</span>
        <span class="c1">#Batch size = 1</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1"># Forward pass</span>
        <span class="n">dense1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">activation1</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dense1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">dense2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">activation1</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">activation2</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dense2</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        <span class="n">dense3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">activation2</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">activation3</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dense3</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>

        
        <span class="c1"># Loss</span>
        <span class="n">testloss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="o">.</span><span class="n">calculate</span><span class="p">(</span><span class="n">activation3</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        
        <span class="n">avetestloss</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">testloss</span><span class="p">)</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch: </span><span class="si">{}</span><span class="s2">, Train loss: </span><span class="si">{}</span><span class="s2">, Test loss </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">avetrainloss</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">avetestloss</span><span class="p">)))</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 0, Train loss: 1.8713897446185137, Test loss 1.8352309081299791
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 1, Train loss: 1.8458849419701862, Test loss 1.837242097022344
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 2, Train loss: 1.8440920276615156, Test loss 1.8382616557603193
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 3, Train loss: 1.8433408619116616, Test loss 1.8388921651452335
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 4, Train loss: 1.8429196210901277, Test loss 1.8393242646608912
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 5, Train loss: 1.8426489643322799, Test loss 1.8396389059044977
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 6, Train loss: 1.8424606853990588, Test loss 1.8398774386572163
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 7, Train loss: 1.8423226551801477, Test loss 1.8400635624495474
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 8, Train loss: 1.842217598685461, Test loss 1.8402120555555852
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 9, Train loss: 1.8421353241399492, Test loss 1.8403325325324296
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 10, Train loss: 1.8420693869286362, Test loss 1.8404318437476124
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 11, Train loss: 1.842015624797165, Test loss 1.8405146501682828
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 12, Train loss: 1.841971070204426, Test loss 1.8405844052986147
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 13, Train loss: 1.841933642080881, Test loss 1.8406437314558017
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 14, Train loss: 1.841901855124302, Test loss 1.8406945810317663
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 15, Train loss: 1.8418745715074147, Test loss 1.840738468345467
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 16, Train loss: 1.8418509326057138, Test loss 1.8407765620391343
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 17, Train loss: 1.8418302859477473, Test loss 1.8408098246705304
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 18, Train loss: 1.841812111926405, Test loss 1.8408389906938454
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 19, Train loss: 1.8417960025203817, Test loss 1.8408646708374985
</pre></div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "env-jupyterbook"
        },
        kernelOptions: {
            kernelName: "env-jupyterbook",
            path: "./docs/neuralnetworks/local"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'env-jupyterbook'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="../local.html" title="previous page">Using Local Machine</a>
    <a class='right-next' id="next-link" href="../../datasets/datasets.html" title="next page">Datasets</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Emmanuel Decena<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
    
  <script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>


    
  </body>
</html>